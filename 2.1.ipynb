{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bdade3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\AADESH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\AADESH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\AADESH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, GlobalMaxPooling1D, LSTM, Dropout, Embedding, Bidirectional\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb616479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "ner_dataset = load_dataset(\n",
    "    \"tner/bc5cdr\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85a9ac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is a dictionary with 3 splits: \n",
      "\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'tags'],\n",
      "        num_rows: 5228\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'tags'],\n",
      "        num_rows: 5330\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'tags'],\n",
      "        num_rows: 5865\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(f'The dataset is a dictionary with {len(ner_dataset)} splits: \\n\\n{ner_dataset}')\n",
    "# It  may be useful to obtain the data in a list format for some sequence tagging methods\n",
    "train_sentences_ner = [item['tokens'] for item in ner_dataset['train']]\n",
    "train_labels_ner = [[str(tag) for tag in item['tags']] for item in ner_dataset['train']]\n",
    "\n",
    "val_sentences_ner = [item['tokens'] for item in ner_dataset['validation']]\n",
    "val_labels_ner = [[str(tag) for tag in item['tags']] for item in ner_dataset['validation']]\n",
    "\n",
    "test_sentences_ner = [item['tokens'] for item in ner_dataset['test']]\n",
    "test_labels_ner = [[str(tag) for tag in item['tags']] for item in ner_dataset['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60acb345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '3', '4'], dtype='<U1')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the different tag values in the dataset:\n",
    "np.unique(np.concatenate(train_labels_ner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad828c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, AdamW, get_linear_schedule_with_warmup, DataCollatorForTokenClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# An example of how to use tokenize_and_align:\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\") \n",
    "label_all_tokens=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "723da5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, max_length=128, is_split_into_words=True)\n",
    "    print(tokenized_inputs.keys())\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "#tokenising\n",
    "tokenized_dataset = ner_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c10207bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#initialising the model\n",
    "num_labels=5 #0,1,2,3,4\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "843fd7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data collation\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91a9ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric\n",
    "from datasets import load_metric\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions,axis=2)\n",
    "    \n",
    "    true_labels=[[label for label in label_row if label != -100] for label_row in labels]\n",
    "    true_predictions = [[pred for pred, label in zip(prediction_row,label_row) if label != -100] for prediction_row, label_row in zip(predictions, labels)]\n",
    "    results = metric.compute(predictions = true_predictions, references=true_labels)\n",
    "    \n",
    "    return {\n",
    "        \"precision\":results[\"overall_precision\"],\n",
    "        \"recall\":results[\"overall_recall\"],\n",
    "        \"f1\":results[\"overall_f1\"],\n",
    "        \"accuracy\":results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c7eb4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training args\n",
    "training_args = TrainingArguments(output_dir=\"./results\",\n",
    "evaluation_strategy=\"steps\",\n",
    "eval_steps=500,\n",
    "logging_steps=500,\n",
    "save_steps=500,\n",
    "num_train_epochs=3,\n",
    "learning_rate=4e-5,\n",
    "weight_decay=0.01,\n",
    "per_device_train_batch_size=16,\n",
    "per_device_eval_batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3861ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising training\n",
    "trainer = Trainer(\n",
    "model=model,\n",
    "args=training_args,\n",
    "train_dataset=tokenized_dataset[\"train\"],\n",
    "eval_dataset=tokenized_dataset[\"validation\"],\n",
    "data_collator=data_collator,\n",
    "tokenizer=tokenizer,\n",
    "compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c81dc1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1635' max='1635' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1635/1635 1:01:57, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.238000</td>\n",
       "      <td>0.144953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.954264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.113900</td>\n",
       "      <td>0.122040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.961260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.083900</td>\n",
       "      <td>0.124978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.960596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1635, training_loss=0.1396595042050796, metrics={'train_runtime': 3718.4745, 'train_samples_per_second': 7.03, 'train_steps_per_second': 0.44, 'total_flos': 54101504867400.0, 'train_loss': 0.1396595042050796, 'epoch': 5.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25b78d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.12452159821987152,\n",
       " 'eval_precision': 0.0,\n",
       " 'eval_recall': 0.0,\n",
       " 'eval_f1': 0.0,\n",
       " 'eval_accuracy': 0.9607252147623788,\n",
       " 'eval_runtime': 205.9416,\n",
       " 'eval_samples_per_second': 25.881,\n",
       " 'eval_steps_per_second': 1.622,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6e6ceb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#applying on test set\n",
    "predictions,labels, _ = trainer.predict(tokenized_dataset[\"test\"])\n",
    "predictions=np.argmax(predictions,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57b64b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3228\n",
      "           1       0.92      0.80      0.85       150\n",
      "           2       0.68      0.77      0.72       121\n",
      "           3       0.62      0.91      0.74        54\n",
      "           4       0.53      0.80      0.64        10\n",
      "\n",
      "    accuracy                           0.96      3563\n",
      "   macro avg       0.75      0.85      0.79      3563\n",
      "weighted avg       0.97      0.96      0.97      3563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#applying on small dataset\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def flatten_list(nested_list):\n",
    "    return [item for sublist in nested_list for item in sublist]\n",
    "small_test_dataset = tokenized_dataset[\"test\"].select(range(200))\n",
    "predictions, labels, _ = trainer.predict(small_test_dataset)\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "true_labels = [[label for label in label if label != -100] for label in labels]\n",
    "true_predictions = [\n",
    "    [p for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "flat_true_labels = flatten_list(true_labels)\n",
    "flat_true_predictions = flatten_list(true_predictions)\n",
    "print(classification_report(flat_true_labels, flat_true_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_analytics",
   "language": "python",
   "name": "text_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
